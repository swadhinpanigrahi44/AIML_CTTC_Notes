{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25eda09-5ad5-414d-b752-89406309e67c",
   "metadata": {},
   "source": [
    "# NLP: \"Natural Language processing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7dab26f-4ab4-4dcc-865a-690cce26b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO IMPORT NLP\n",
    "import nltk #nltk : Natuarl Language Tool Kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd09497e-d4b0-47ed-8443-9378b0418d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to download nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14bdd32f-0e33-4e29-ac7d-8a468444a436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Love mathematics. Wait for a while. I love to eat paneer.Next sunday we are going to attend AIML class\n"
     ]
    }
   ],
   "source": [
    "txt = \"I Love mathematics. Wait for a while. I love to eat paneer.Next sunday we are going to attend AIML class\"\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f410e-938e-4f32-a2ec-fd241349f094",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb90001c-4f45-4aa7-94eb-00a20fdf0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "sent_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7528ee6-5ca9-4c41-bd97-9fe622806bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "word_tokenize(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11dad17-11be-42fb-8de5-9b219c42137f",
   "metadata": {},
   "source": [
    "### Stemming: It finds the nearest rootword by spelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7b4b9-766a-4a73-a33e-9f3d7da73ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e09fdf-a821-412c-a6fb-144961746b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.stem('CARS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247140cc-56a1-474c-931b-31b3097ea1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.stem('happiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bfb061-aeff-4254-a166-3733c5f999d6",
   "metadata": {},
   "source": [
    "### Lemmatization: It finds the nearest rootword by meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4b2e2-e300-4e0b-99d0-f46a8991bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79cbccd-b2ad-4dd6-b76e-178d0ec8a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.lemmatize('went','v') # you can check the details by clicking the cursor some where and by tapping shift + tab - 'n','a','v' etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8208b0-26bc-43ab-a428-9af7b264ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.lemmatize('eaten','v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88187e6d-4cc3-49fb-9e60-8456cb7b88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.lemmatize('studied','v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe0ef3-5ec6-4522-8131-2fed8d70db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.lemmatize('goodness','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188aadf3-8cfc-4b95-9a5c-4620ee6300ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords - commonly used words\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english') # you can also check other popular languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9382ebf-e682-47d8-90a9-a0c0593da616",
   "metadata": {},
   "source": [
    "### POS Tags - Part Of Speech Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9fd55f-498b-4b28-bd1b-748b0bd9c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'Mount Everest is the highest peak in the world'\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12793032-7e5d-4bee-bc67-8f0cf2ba59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_token = word_tokenize(txt)\n",
    "txt_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685cfe8e-65c9-47cd-88b2-3a48d08e5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_tag = nltk.pos_tag(txt_token)\n",
    "txt_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28dc7e-4d81-4dc7-aa70-2bdb2938b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gfgerwvvfgrw43y674ytthjjyhhfhdjuhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhklllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaallllllllllllmmmmmmmmmmmmmmmmmaaaaaaaaaaaaaaaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcaac0d-bd20-4e5e-a7f4-06536abedb8a",
   "metadata": {},
   "source": [
    "### ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d0d00-c9ba-4dbd-8947-f19e6a3fe7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'Narendra Modi is the Prime Minister of India'\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ef3b3-5185-48e1-9087-5e5a96f0aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_token = word_tokenize(txt)\n",
    "txt_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6d13a-25f6-4790-afed-ce4fad64dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_tags = nltk.pos_tag(txt_token)\n",
    "txt_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43c2c8-4f04-4d33-b480-1d95329f3919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk\n",
    "\n",
    "txt_chunk = ne_chunk(txt_tags)\n",
    "print(txt_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce701cd-d378-410e-a88e-f9b9fa5b37fd",
   "metadata": {},
   "source": [
    "### Vectorizer: It is used to identify the importance of the word in a sentence\n",
    "It is of 2 Types:\n",
    "1. Count Vectorizer\n",
    "2. TFIDF Vectorizer\n",
    "\n",
    "#### Count Vectorizer: \n",
    "Count Vectorizer is a method used in NLP to convert text documnets into a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419366b3-16d6-4d54-8847-ca5fa08650ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "from sklearn.feature_extraction.txt import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "txt = [\"I love singing and painting\"]\n",
    "\n",
    "x = cv.fit_transform(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96176e42-7b5c-4b1f-920f-6a59b178eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14274e5e-839f-42ff-bef4-bd891d899f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88041ded-c97c-4aca-8149-a5fa73f2c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33ea09-7096-49a7-b56d-6bf019b81c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0629110-70ed-4b5e-8ea6-abddd1635ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [\"I love Singing and I love Painting\", \"I love ice-cream\"]\n",
    "y = cv.fit_transform(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4904c74-59f4-430c-90d6-40dcc336fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c761b0b-0e29-4f12-98e3-e83620e34fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c6743-d3c7-465b-a23d-bd72d8025632",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa83292-016e-4c1e-abf5-84fda094712b",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer\n",
    "1. Term frequency-inverse document frequency(TF-IDF) gives a measure that takes the importance of a word into consideration depending on how frequently it occurs in a document  and a corpus.\n",
    "2. To understand TF-IDF ,firstly we will understand the two terms separate\n",
    "\n",
    "### TF:\n",
    "It is defined as the number of times a word (i appear in a document[j] divided by total numbers of word in the document).\n",
    "\n",
    "### IDF:\n",
    "It is defined as the log of total number of document divided by the number of documents that contents the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a377b6-e6e1-442d-aa8a-2a395fe9985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "txt = [\"I love Singing and I love Painting\", \"I love ice-cream\"]\n",
    "z = tfidf.fit_transform(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad217c9-a38e-46b8-9c0e-5bf65df5ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d15c3-af47-4c08-a9f2-797c6cf75067",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234abf7-d146-4149-8763-ce699ba8dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a446c0-f074-45ef-8803-9ce4b37d19c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ae467-ee4a-4248-8380-6d8135eb6dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc1598-0a9e-4ba5-93a0-ac12bcaeacad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbc925-2033-4cda-99f5-9bb7eca3b077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
